\documentclass[11 pt]{scrartcl}
\usepackage[header, margin, koma, stylish]{tyler}
\usepackage{csquotes}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[l]{EECS 127 Notes}
\fancyhead[r]{Tyler Zhu}
\cfoot{\thepage}

\begin{document} 
\title{\Large EECS 127: Optimization Models in Engineering}
\author{\large Tyler Zhu}
\date{\large\today}

\maketitle 

\begin{center}
\begin{displayquote}
    \emph{"A good stock of examples, as large as possible, is indispensable for a thorough understanding of any concept, and when I want to learn something new, I make it my first job to build one."} \\ \begin{flushright} \emph{â€“ Paul Halmos}.  \end{flushright}
\end{displayquote}
\end{center}


These are course notes for the Spring 2021 rendition of EECS 127, Optimization Models in Engineering, taught by Professor Laurent El Ghaoui.

\tableofcontents 

\newpage

\section{Tuesday, January 19th}
\subsection{Introduction}
In this course, we'll be talking primarily about \emph{optimization}. 
A standard form of optimization is the following: 
\[ p^* = \min_\vx f_0(\vx)\quad \text{subject to: } f_i(\vx) \leq 0,\; i=1,\dots, m,\] 
where 
\itemnum
    \ii vector $\vx\in \RR^n$ is the \emph{decision variable}; 
    \ii $f_0: \RR^n \to \RR$ is the \emph{objective} function, or \emph{cost}; 
    \ii $f_i: \RR^n\to \RR$, $i=1,\dots, m$, represent the \emph{constraints}; 
    \ii $p^*$ is the \emph{optimal value}. 
\itemend

Realistically, $\vx = [x_1\; \dots\; x_n]$ represents different decisions, i.e. $x_2$ would be our decision at time $t=2$. 
Also note that we can easily solve instead to maximize some $r(x)$ by setting $f_0(x) = -r(x)$. 
This above setup is known as the \emph{standard form}. 

Oftentimes we will have multiple optimal solutions to the constraint, in which case any $x^* \in \arg\min f_0(x)$ for which $f_i(x^*) \leq 0, i=1, \dots, m$ is satisfied acts as an optimizer.

In this class, we're not as concerned with algorithms for optimization, but more so translating problems from the real world into this language. 

\begin{example}[Least-squares regression]
A classic example in machine learning is when we have a given vector $y$ and we're trying to express it as a linear function of an input vector $z$, i.e. data points. 
The goal is the solve the objective 
\[ \min_x \sum_{i=1}^m (y_i - x^\T z^{(i)})^2\] 
where 
\itemnum
    \ii $z^{(i)}\in \RR^n$, $i=1, \dots, n$ are data points; 
    \ii $y\in \RR^m$ is a ``response'' vector; 
    \ii $x^\T z$ is the scalar product $z_1x_1+\dots + z_nx_n$ b/w the two vectors $x,z \in \RR^n$. 
\itemend

One example of constraints we could be working with are $x\geq 0$ and $x^\T \one = 1$, which corresponds to modeling a discrete distribution.

\end{example}

\begin{example}[Support Vector Machines (SVMs)]
In SVMs, we instead are trying to optimize a ``hinge'' loss, i.e. 
\[ \min_{x,b} \sum_{i=1}^m \max(0, 1-y_i(x^\T z^{(i)} + b))\] 
where 
\itemnum
    \ii $z^{(i)}\in \RR^n$, $i=1, \dots, n$ are data points; 
    \ii $y\in \{-1, 1\}^m$ is a \emph{binary} response vector; 
    \ii $x^\T z + b = 0$ defines a ``separating hyperplane'' in data space. 
\itemend

We could imagine that our points are colored green and red.
Then at a conceptual level, we're trying to create a hyperplane that separates our data points into two different classes as clearly as possible. 
Once we find the best $x,b$, we can predict the binary output $\hat{y}$ corresponding to a new point's predicted class.
\end{example}

While we just gave a few machine learning examples which were problems without constraints, we can often use optimization to act on certain situations. 
One example is energy production. 
There's a \textbf{lot} of other ones. 


\subsection{Optimization Problems}
There is more nomenclature we need to know: 
\itemnum
    \ii \emph{Feasible set}, i.e. the set of possible values satisfying the constraints. 
    \ii \emph{Unconstrained minimizer}:$x_0$, i.e. minimizing the cost function without constraints. 
    \ii \emph{Optimal Point}: $x^*$. 
    \ii \emph{Level sets} of objective functions, i.e. sets $\{x | R(x) = c\}$ for some $c$. 
    \ii \emph{Sub-level sets}, i.e. sets $\{ x | R(x) \leq c\}$ for some $c$. 
\itemend
Usually our optimal points will be some intersection with the smallest level sets and the feasible set. 

Similar to neural networks, we can have an issue in optimization of local vs. global optimal points. 
A point $z$ is \emph{locally optimal} if there exists a value $R>0$ such that $z$ is optimal for problem 
\[ \min_x\; f_0(x) \text{ s.t. } f_i(x) \leq 0,\;  i=1, \dots, m \text{ and } |x_i - z_i| \leq R,\; i=1, \dots, n.\] 

A local minimizer $x$ minimizes $f_0$, but only compared to nearby points on the feasible set. 
The value of the objective function at that point is \emph{not} necessarily the (global) optimal value of the problem. 
Locally optimal points might be of no practical interest to the user. 
Visually, you could imagine that we could find ourselves in certain pits that locally seem like optima but globally are far from it. 

Due to these problems (and others), often times even coming up with any minimizer can be difficult. 
However, there's a special class of problems called \emph{convex problems} which have the nice property that \emph{all} local optimums are also global optimums.
Usually your objective function when plotted looks something like a bowl, i.e. there's a single point at the bottom which is the previously mentioned global optimum.

\begin{figure}[!htb]
    \caption{Convex and Non-convex functions (missing!)}
\end{figure}

Funny enough, even though most problems are non-convex, we could find a convex function that lower bounds our objective function and hope its global optimum is a decent solution to our original objective. 
Pushing this further, if we could find the tightest convex function which is a lower bound (think convex hulls), then its optimal point \emph{is} the same as our original's! 
It looks like we just turned a hard problem into a much easier one, but we unfortunately have no idea how to find this convex-hull. 
Back to square one. 

\subsection{Course Outline}

In this course, we shall deal specifically with convex optimization problems with special structure, such as: 
\itemnum
    \ii Least-Squares (LS)
    \ii Linear Programs (LP)
    \ii Convex Quadratic Program (QP)
    \ii Second-order cone programs (SOCP)
\itemend

For such specific models, very efficient solution algorithms exist with high quality implementations/software (CVX, for example). 
Most of the problems we come across can be categorized into one of the above structures, as we'll come to see. 

A large part of our time will be spent talking about affine subspaces, and normal vectors to hyperplanes to geometrically construct feasible sets. 

We'll also discuss a few non-convex problems that come up often in the real world: 
\itemnum
    \ii \emph{Boolean/integer optimization}: $x_i\in \{0,1\}^n$; some variables are constrained to be Boolean or integers. Convex optimization can be used for getting (sometimes) good approximations. 
    \ii \emph{Cardinality-constrained problems}: we seek to bound the number of non-zero elements in a vector variable. Convex optimization can be used for getting good approximations. 
    \ii \emph{Non-linear programming}: usually non-convex problems with differentiable objective and functions. Algorithms provide only local minima. 
\itemend

It goes without saying that most (but not all) non-convex problems are \emph{hard}!

For example, let's look at boolean optimization. We would like to solve $\min_{\vx} c^\T \vx$ subject to $A\vx \leq b$ and $\vx\in \{0,1\}^n$. 
One way of relaxing this into a problem that's easier to solve is to consider instead $\vx \in [0,1]^n$, i.e. going from discrete to continuous feasible set.
This is an important question because this allows us to do sparsity and feature-selection. 

What this course is for: 
\itemnum
    \ii Learning to model and efficiently solve problems arising in Engineering, Management, Control, Finance, ML, etc. 
    \ii Learning to prototype small- to medium- sized problems on numerical computing platforms. 
    \ii Learning basics of applied linear algebra, convex optimization.
\itemend

What this course is NOT: 
\itemnum
    \ii A course on mathematical convex analysis.
    \ii A course on details of optimization algorithms. 
\itemend

Here's a high level overview of what we're talking about: 
\itemnum
    \ii Linear algebra models 
    \itemnum
        \ii Vectors, projection theorem, matrices, symmetric matrices.
        \ii Linear equation, least-squares and minimum-norm problems.
        \ii Singular value decomposition (SVD), PCA, and related optimization problems. 
    \itemend
    \ii Convex optimization models 
    \itemnum
        \ii Convex sets, convex functions, convex problems. 
        \ii Optimality conditions, duality. 
        \ii Special convex models: LP, QP, SOCP.
    \itemend
    \ii Applications 
    \itemnum
        \ii Machine Learning.
        \ii Control.
        \ii Finance.
        \ii Engineering desisgn.
    \itemend
\itemend

There will only be six homeworks in this course.

\newpage
\section{Thursday, January 21st}
Today's lecture went pretty fast and sped through sections, so likewise these notes are pretty rough. 
Also I don't have time to add pictures (unless I rip them off from somewhere), so I hope you have Beth Harmon level visualization powers. 

\subsection{Introduction}
We usually write vectors in column format, i.e. 
\[ x = \colvec{4}{x_1}{x_2}{\vdots}{x_n}.\] 
Element $x_i$ is the $i$th component, and the number $n$ of components is the \emph{dimension} of $x$. 
Importantly, in math, we always 1-index, not 0-index. 

We can use vectors for example in bag of words frequency matching.

\begin{example}[Time series]
    We can model a time series, i.e. the evolution of a physical or economical quantity. 
    We can represent it like $x = [x(1)\; x(2)\; \dots\; x(T)]^\T\in\RR^T$ where each $x(k)$ is the value of the quantity at time $k$.

    One example of a model for time series is an ``auto-regressive'' model, where we assume that the output depends linearly on certain previous terms and some stochasticity (i.e. error). 
    For example, if we think it only depends on the previous two days, we could write that 
    \[ x_t \approx \alpha_1 x_{t-1} + \alpha_2 x_{t-2} + \text{error}.\]
\end{example}

Now for a list of definitions... 

Vectors have a few special properties, in that the operations of sum, difference, and scalar multiplication all hold and are closed, i.e. that they return other vectors. 
These properties define a \emph{vector space}. 
The simplest example is $\Xcal = \RR^n$. 

From a vector space $\Xcal$, a nonempty subset $\mathcal{V}$ of $\Xcal$ is a \emph{subspace} if, for any scalars $\alpha, \beta$, 
\[ x,y \in \mathcal{V} \implies \alpha x + \beta y \in \mathcal{V}.\] 
For example, the set of all possible linear combinations of vectors in $S = \{x^{(1)}, \dots, x^{(m)}\}$ forms a subspace called the \emph{span} of $S$, denoted as $\spn(S)$. 

Finally, given two subspaces $\Xcal, \Ycal$ in $\RR^n$, the \emph{direct sum} of $\Xcal, \Ycal$, denoted by $\Xcal\oplus \Ycal$, is the set of vectors of the form $x+y$ with $x\in \Xcal, y\in \Ycal$. 
One can easily check that $\Xcal\oplus\Ycal$ is a subspace. 

We also have the familiar concepts of linear independence and hence the \emph{basis} for a subspace, whose cardinality defines the dimension of the subspace.

\begin{definition}[Affine sets]
    An affine set is a set of the form 
    \[ \Acal = \{x\in \Xcal\; | x = v+x^{(0)}, v\in \Vcal\},\] 
    where $x^{(0)}$ is a given point and $\Vcal$ is a given subspace of $\Xcal$. 
    Subspaces are affine spaces containing the origin (i.e. $x^{(0)}$ is the origin). 
\end{definition}

Naturally, a \emph{line} is a one-dimensional affine set. 
We start with some point $x_0$ which hinges the line, and then some vector $v$ which determines the direction (i.e. including all multiples of it). 

Quick quiz: how many values do we need to uniquely determine lines in 2D? 
You might think it's 2, but we need to identify the vertical line as well, so it's 3. 
Think of $ax+by+c=0$. 

One question we might have is how do we measure the \emph{size} of a vector; norms are the answer to this question. 
In short, a \emph{norm} simply assigns real numbers to vectors in a consistent manner, i.e. it satisfies the following properties: 
\begin{definition}[Norm]

\end{definition}

We will primarily use three norms: 
\itemnum
    \ii For $p=2$, we obtain the standard Euclidean length 
    \[ \|x\|_2 = \sqrt{\sum_{k=1}^n x_k^2},\] 
    \ii or $p=1$ which gives the sum-of-absolute-values length (or Manhattan distance) 
    \[ \|x\|_1 = \sum_{k=1}^n |x_k|.\] 
    \ii When $p=\infty$ defines the $\ell_\infty$ norm (max absolute value norm) 
    \[ \|x\|_{\infty} = \max_{k=1,\dots, n} |x_k|.\] 
    \ii The cardinality of a vector $x$ is often called the $\ell_0$ (pseudo-) norm, which
\itemend

\subsection{Inner product, orthogonality}
Inner products are interesting since we can think of vectors now as functions acting on other vectors, i.e. like $\cyc{x, \cdot}$. 
\begin{definition}[Inner product]
    An \emph{inner product} on a (real) vector space $\Xcal$ is a real-valued function which maps pairs $x,y\in \Xcal$ into a scalar denoted by $\cyc{x,y}$. 
    The inner product satisfies the following axioms (for $x,y,z\in \Xcal$ and scalar $\alpha$):
    \begin{align*}
        \cyc{x,x} \geq 0;  
    \end{align*}
\end{definition}

A vector space with an inner product is called an \emph{inner product space}, and the standard inner product in $\RR^n$ is the row-column product of two vectors, 
\[ \cyc{x,y} = x^\T y = \sum_{k=1}^n x_ky_k.\] 
Finally, inner products also induce a norm given by $\|x\| = \sqrt{\cyc{x,x}}$ (which you may notice is identical to the $\ell_2$-norm in $\RR^n$). 

With inner products, we can define the angle $\theta$ between two vectors $x,y$ by 
\[ \cos \theta = \dfrac{x^\T y}{\|x\|_2\|y\|_2},\]
which results from doing some easy geometry. 
This lets us characterize when $x,y$ are \emph{orthogonal} (i.e. $\theta = \pm 90^\circ$), and when $x,y$ are \emph{parallel} (i.e. $\theta = 0^\circ, \pm 180^\circ$). 

Since $|\cos\theta| \leq 1$, we easily get the following inequality. 
\begin{theorem}[Cauchy-Schwarz Inequality]
    For vectors $x,y\in \RR^n$, 
    \[ |x^\T y| \leq \|x\|_2 \|y\|_2\] 
    where inequality holds when $x = \alpha y$ for scalar $\alpha$ (i.e. when $|\cos\theta| = 1$). 
\end{theorem}

We also have the following generalization with $\ell_p$ norms. 
\begin{theorem}[Holder's Inequality]
    For any vectors $x,y\in \RR^n$ and for any $p,q \geq 1$ such that $1/p + 1/q = 1$, it holds that 
    \[ |x^\T y| \leq \sum_{k=1}^n|x_ky_k| \leq \|x\|_p \|y\|_q.\] 
\end{theorem}

As a quick aside, let's discuss maximizing the inner product over norm balls. 
In other words, we're trying to solve the optimization problem 
\[ \max_{\|x\|_p\leq 1} x^\T y.\] 

For $p=2$, ... 


For generic inner product spaces, we say that two vectors $x,y$ in an inner product space $\Xcal$ are \emph{orthogonal} if $\cyc{x,y} = 0$, which we denote by $x\perp y$. 
Nonzero vectors are \emph{mutually orthogonal} if they are pairwise orthogonal. 


We have an important theorem concerning projections.
\begin{theorem}[Projection Theorem]
    Let $\Xcal$ be an inner product space, $x$ be a given element in $\Xcal$, and $\Scal$ a subspace of $\Xcal$. 
    Then, there exists a unique vector $x^*\in \Scal$ which is the solution to the problem 
    \[ \min_{y\in\Scal} \|y-x\|.\] 
    Moreover, a necessary and sufficient condition for $x^*$ being the optimal solution for this problem is that $x^*\in \Scal,\; (x-x^*)\perp \Scal$. 
\end{theorem}

Let $p\in \RR^n$ be a given point. 
We want to compute the Euclidean projection $p^*$ of $p$ onto a line $L = \{x_0 + \spn(u)\}$, $\|u\|_2 = 1$. 
%For example, we can write this simply as 

Now say we want to solve the harder problem of projecting onto a span of vectors, say $\Scal = \spn(x^{(1)}, \dots, x^{(d)})\subseteq \Xcal$. 
By the projection theorem, we can convert this into a system of equations and solve. 


\subsection{Functions and maps}
In this class, we usually reserve the term \emph{function} to denote $f: \RR^n\to \RR$, and use the term \emph{map} when $f: \RR^n \to \RR^m$ and $m > 1$.

A \emph{linear} function is simply a function that perserves scaling and additivity, i.e. that 
\begin{align*}
    f(\alpha x) &= \alpha f(x) \quad\forall x\in \RR^n, \alpha\in\RR \\ 
    f(x + y) &= f(x) + f(y) \quad\forall x,y\in \RR^n.
\end{align*}

The gradient of a function can be intepreted in the context of level sets. 
Geometrically, the gradient of $f$ at a point $x_0$ is a vector $\nabla f(x_0)$ perpendicular to the contour line of $f$ at level $\alpha = f(x_0)$, pointing from $x_0$ outwards the $\alpha$-sublevel set (i.e. points towards higher values of the function). 


\end{document}
